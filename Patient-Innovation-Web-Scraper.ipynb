{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3efa61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "import requests as r \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import numpy as array \n",
    "import chromedriver_autoinstaller \n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_dict  ={}\n",
    "no_of_solutions = 1\n",
    "tags_frame = {}\n",
    "no_of_rows = 1\n",
    "comments_frame = {}\n",
    "no_of_com = 1\n",
    "i = 1\n",
    "page_starter = input(\"From which page do you want to start?: \")\n",
    "page_starter = int(page_starter)\n",
    "page_counter = input(\"HOW MANY PAEGES YOU WANT TO SCRAPE?(min 2)\")\n",
    "page_counter = int(page_counter)\n",
    "while i < page_counter:\n",
    "    # Fetching the main page for solutions \n",
    "    url = f\"https://patient-innovation.com/browse?vid=All&sort_by=created&page={str(page_starter)}\"\n",
    "    print(url)\n",
    "    res = r.get(url)\n",
    "    data = res.text\n",
    "    soup = bs(data, 'html.parser')\n",
    "    ul = soup.find('ul',{'class':\"latestSolutionsHome search-cards-list clearfix\"})\n",
    "    solutions = ul.find_all('li')\n",
    "    sol_links = []\n",
    "    for solution in solutions:\n",
    "        try:\n",
    "            link = solution.find('a').get('href')\n",
    "            if \"post/\" in link:\n",
    "                print(link)\n",
    "                sol_links.append(link)\n",
    "        except:\n",
    "            pass\n",
    "    # Going through solutions \n",
    "    for sol_link in sol_links:\n",
    "        res = r.get(f\"https://patient-innovation.com{sol_link}\")\n",
    "        print(f\"https://patient-innovation.com{sol_link}\")\n",
    "        data = res.text\n",
    "        soup = bs(data, 'html.parser')\n",
    "        stats = soup.find('ul',{'class':'solution-stats-list'})\n",
    "        title = soup.find('h1',{'class':\"solution-title\"}).text.strip()\n",
    "        views = stats.find('li').text.strip()\n",
    "        likes = stats.find('span',{'class':'likes-counter'}).text.strip()\n",
    "        boughts = stats.find('span',{'class':'boughts-counter'}).text.strip()\n",
    "        copies = stats.find('span',{'class':'copies-counter'}).text.strip()\n",
    "        no_of_comments = stats.find_all('li')[4].text.strip()\n",
    "        dates = soup.find('p',{'class':\"solution-desc-info\"}).text.strip()[-16:-5]\n",
    "        # About the author \n",
    "        about_author = soup.find('div',{'class':{\"about-author-content\"}}).find('p').text.strip()\n",
    "        # tags \n",
    "        tags = \"\"\n",
    "        tags_list = soup.find('ul',{\"class\":\"solution-tags-list\"}).find_all('li')\n",
    "        for tag in tags_list:\n",
    "            tags_frame[no_of_rows] = [title,tag.text.strip()]\n",
    "            no_of_rows += 1\n",
    "        # Comments \n",
    "        comments_list = soup.find_all('div',{'class':\"solution-comments-content\"})\n",
    "        if len(comments_list)>0: \n",
    "            for comment in comments_list:\n",
    "                comments_frame[no_of_com]= [title, comment.find_all('p')[1].text.strip()]\n",
    "                no_of_com += 1\n",
    "        else:\n",
    "            comments_frame[no_of_com] = [title,\"No comments Found\"]\n",
    "            no_of_com +=1 \n",
    "        about_solution = soup.find('div',{'class':\"about-solution-content\"}).text.strip()\n",
    "        solution_dict[no_of_solutions] = [title,dates,likes ,no_of_comments,views, boughts,copies,about_author,about_solution]\n",
    "        print(solution_dict[no_of_solutions])\n",
    "        no_of_solutions += 1\n",
    "        sleep(2)\n",
    "    i += 1\n",
    "    page_starter += 1\n",
    "df = pd.DataFrame.from_dict(solution_dict, orient=\"index\", columns=[\"Title\",\"Date Posted\",\"Hearts - Like Solution\", \"No of Comments\", \"Views\",\"Bag - I brought this solution\", \"Copy- I made a Copy of this\", \"About the author\",  \"About the Solution\"])\n",
    "df.to_csv(\"Solutions.csv\")\n",
    "tags_df = pd.DataFrame.from_dict(tags_frame, orient=\"index\", columns=[\"Title\",\"tags\"])\n",
    "tags_df.to_csv(\"tags.csv\")\n",
    "\n",
    "comments_df = pd.DataFrame.from_dict(comments_frame, orient=\"index\", columns=[\"Title\",\"Comments\"])\n",
    "comments_df.to_csv(\"Comments.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
